
```markdown
# Project Name
Drug Molecule Property Prediction :
This project implements deep learning models to predict molecular properties from SMILES strings, aiming to assist in drug design by optimizing molecule selection.

## ğŸš€ Features

- Dual-Model Architecture
- Production-Ready Deployment


## Models

Model1: Feature-Based Prediction
Input: Extracted molecular features (using RDKit fingerprints)

Architecture: Deep neural network

Usage:
aman-predict_model2=src.predict_model1:main

Model2: SMILES String Prediction
Input: Raw SMILES string (character-level processing)

Architecture: LSTM-based network


## ğŸ› ï¸ Tech Stack

- Language: Python
- Framework: Flask, TensorFLow, RDKit
- Other tools: Docker, 

## ğŸ“¦ Installation

Clone the repo:

```bash
git clone https://github.com/Oussama-nasri/aman-ai-test.git
cd aman-ai-test

```

Install dependencies:

```bash
conda create -n aman python=3.6
conda activate aman
conda install -c conda-forge rdkit

pip install -r src/requirements.txt
pip install -e .
```

## ğŸ§ª Usage

Train models localy

```bash
aman-train_model1=src.train_model1:main --data_path

aman-train_model2=src.train_model1:main --data_path
```

Predict P1 with models localy

```bash
aman-predict_model1= --smiles
aman-predict_model2= --smiles
```

Evaluate Models
```bash
aman-predict_model1=src.predict_model1:main --test_dataset_path= --model_path=
aman-predict_model1=src.predict_model2:main --test_dataset_path= --model_path=  --tokenizer_path=
```


Running API
```bash
python src/app.py
```
Visit `http://127.0.0.1:5000/docs/#/default/post_predict` in your browser.

Fill the model with a valid molecule smile and the id of the model you want to use:

{
  "smiles": "COC(=O)c1ccc(Oc2nc(NC(C)C)nc(SC)n2)cc1",
  "model": 2
}

Docker Depolyment
```bash
docker build -t aman -f src/Dockerfile .
docker run -p 5000:5000 aman
```


## Project Structure
```bash

TEST_TECHNIQUE/
â”œâ”€â”€ aman.egg-info/          # Python package metadata
â”œâ”€â”€ api/                    # API implementation
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ routes.py           # API endpoint definitions
â”œâ”€â”€ data/                   # Data files
â”‚   â”œâ”€â”€ model1/             # Model1 specific data
â”‚   â”‚   â”œâ”€â”€ test_data.csv
â”‚   â”‚   â””â”€â”€ train_data.csv
â”‚   â”œâ”€â”€ balanced_dataset_single.csv
â”‚   â”œâ”€â”€ dataset_multi.csv
â”‚   â””â”€â”€ dataset_single.csv
â”œâ”€â”€ models/                 # Trained models and assets
â”‚   â”œâ”€â”€ model1.joblib
â”‚   â”œâ”€â”€ smiles_transformer.h5
â”‚   â”œâ”€â”€ tokenizer.json
â”‚   â””â”€â”€ tokenizer.pkl
â”œâ”€â”€ notebooks/              # Jupyter notebooks (if any)
â””â”€â”€ src/                    # Main source code
    â”œâ”€â”€ __pycache__/
    â”œâ”€â”€ data_separation.py  # Data splitting utilities
    â”œâ”€â”€ evaluate.py         # Model evaluation
    â”œâ”€â”€ feature_extractor.py # Molecule feature extraction
    â”œâ”€â”€ predict_model1.py   # Model1 prediction
    â”œâ”€â”€ predict_model2.py   # Model2 prediction
    â”œâ”€â”€ train_model1.py     # Model1 training
    â”œâ”€â”€ train_model2.py     # Model2 training
    â”œâ”€â”€ swagger/            # API documentation
    â”‚   â””â”€â”€ swagger.yml
    â”œâ”€â”€ tests/              # Test cases
    â”œâ”€â”€ .gitignore
    â”œâ”€â”€ app.py              # Flask application
    â”œâ”€â”€ Dockerfile          # Container configuration
    â”œâ”€â”€ README.md           # Documentation
    â”œâ”€â”€ requirements.txt    # Dependencies
    â””â”€â”€ setup.py            # Package configuration
```
## ğŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.


```